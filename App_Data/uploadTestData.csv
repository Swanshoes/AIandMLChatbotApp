Question,Answer
"What is the difference between AI, ML, and deep learning?","AI is the broadest concept of machines performing intelligent tasks, ML is a subset using algorithms to learn from data, and deep learning is a subset of ML using neural networks with multiple layers."
"What is underfitting in machine learning?","Underfitting occurs when a model is too simple to capture underlying data patterns, resulting in poor performance on both training and test data."
"What is the bias-variance tradeoff?","The bias-variance tradeoff balances model simplicity versus complexity, where high bias causes underfitting and high variance causes overfitting, requiring optimization of both."
"What is a decision tree?","A decision tree is a model that splits data using feature-based conditions in a tree structure, making decisions by traversing from root to leaf nodes."
"What is random sampling?","Random sampling selects data points with equal probability, ensuring unbiased dataset creation for training, validation, or testing without systematic selection patterns."
"What is the curse of dimensionality?","The curse of dimensionality describes challenges when feature space becomes very large, causing data sparsity, increased computation, and difficulty finding patterns."
"What is label encoding?","Label encoding converts categorical variables into numerical integers, assigning each unique category a number for use in machine learning algorithms."
"What is target encoding?","Target encoding replaces categorical values with statistics derived from the target variable, such as mean target value for each category."
"What is the ROC curve?","The ROC curve plots true positive rate against false positive rate at various classification thresholds, visualizing model performance across different cutoffs."
"What is AUC in machine learning?","AUC is the Area Under the ROC Curve, measuring a classifier's ability to distinguish between classes, with 1.0 being perfect and 0.5 being random."
"What is log loss?","Log loss measures classification performance by penalizing confident wrong predictions heavily, calculating the negative log-likelihood of true labels given predicted probabilities."
"What is mean squared error?","MSE measures average squared differences between predicted and actual values, heavily penalizing large errors and commonly used for regression tasks."
"What is mean absolute error?","MAE measures average absolute differences between predictions and actuals, treating all errors equally regardless of magnitude, being more robust to outliers."
"What is R-squared?","R-squared measures the proportion of variance in the dependent variable explained by independent variables, ranging from 0 to 1, indicating model fit quality."
"What is root mean squared error?","RMSE is the square root of MSE, providing error measurement in the same units as the target variable, making interpretation easier."
"What is a baseline model?","A baseline model is a simple reference model using basic rules or statistics, providing a performance benchmark that more complex models should exceed."
"What is stratified k-fold cross-validation?","Stratified k-fold CV maintains class proportions in each fold, ensuring balanced representation across all splits, especially important for imbalanced datasets."
"What is leave-one-out cross-validation?","LOOCV trains on all samples except one, repeating for each sample, providing thorough evaluation but being computationally expensive for large datasets."
"What is time series cross-validation?","Time series CV respects temporal ordering by training on past data and validating on future data, preventing data leakage from future information."
"What is grid search?","Grid search exhaustively tries all combinations of specified hyperparameter values, finding the best configuration through systematic evaluation of the search space."
"What is random search?","Random search samples hyperparameter combinations randomly from specified distributions, often finding good configurations faster than grid search with fewer evaluations."
"What is Bayesian optimization?","Bayesian optimization builds probabilistic models of objective functions, intelligently selecting hyperparameters to evaluate by balancing exploration and exploitation."
"What is feature importance?","Feature importance quantifies each feature's contribution to model predictions, helping identify key variables, reduce dimensionality, and understand model behavior."
"What is permutation importance?","Permutation importance measures feature relevance by randomly shuffling feature values and observing prediction degradation, being model-agnostic and considering feature interactions."
"What is LIME?","LIME creates interpretable local approximations of complex models around specific predictions, explaining individual decisions through simpler surrogate models."
"What is the elbow method?","The elbow method identifies optimal cluster numbers by plotting inertia or silhouette scores against cluster counts, finding the point where improvement diminishes."
"What is silhouette score?","Silhouette score measures how similar objects are to their own cluster compared to other clusters, ranging from -1 to 1, with higher values indicating better clustering."
"What is k-means clustering?","K-means partitions data into k clusters by iteratively assigning points to nearest centroids and updating centroids until convergence, minimizing within-cluster variance."
"What is hierarchical clustering?","Hierarchical clustering builds nested cluster trees through agglomerative or divisive approaches, creating dendrograms that show relationships at multiple granularities."
"What is DBSCAN?","DBSCAN is a density-based clustering algorithm that groups closely packed points, identifying clusters of arbitrary shape and marking sparse regions as outliers."
"What is principal component analysis?","PCA reduces dimensionality by projecting data onto orthogonal components that capture maximum variance, transforming features into uncorrelated principal components."
"What is t-SNE?","t-SNE is a dimensionality reduction technique that preserves local structure, projecting high-dimensional data into 2D or 3D for visualization while maintaining neighbor relationships."
"What is UMAP?","UMAP reduces dimensions while preserving both local and global structure, being faster than t-SNE and providing better preservation of data topology."
"What is an autoencoder?","An autoencoder is a neural network that learns compressed representations by encoding inputs to lower dimensions and decoding back, trained to reconstruct inputs."
"What is a denoising autoencoder?","A denoising autoencoder learns robust representations by training to reconstruct clean inputs from corrupted versions, forcing extraction of meaningful underlying features."
"What is word embedding?","Word embeddings represent words as dense vectors capturing semantic relationships, learned from context in large corpora, enabling meaning-based word comparisons."
"What is Word2Vec?","Word2Vec learns word embeddings by predicting context words from target words or vice versa, creating vectors where similar words have similar representations."
"What is GloVe?","GloVe creates word embeddings by factorizing word co-occurrence matrices, capturing both local context and global corpus statistics in vector representations."
"What is BERT?","BERT is a transformer-based language model pre-trained bidirectionally on masked language modeling and next sentence prediction, providing contextualized word representations."
"What is GPT?","GPT is a transformer-based autoregressive language model pre-trained on next token prediction, generating coherent text through unidirectional attention mechanisms."
"What is tokenization?","Tokenization splits text into smaller units like words, subwords, or characters, creating discrete tokens that models can process numerically."
"What is BPE tokenization?","Byte Pair Encoding iteratively merges frequent character pairs to create subword tokens, balancing vocabulary size with representation of rare words."
"What is stemming?","Stemming reduces words to root forms by removing suffixes using simple rules, creating crude but fast text normalization for information retrieval."
"What is lemmatization?","Lemmatization reduces words to dictionary base forms using linguistic knowledge, providing more accurate normalization than stemming but requiring more computation."
"What is TF-IDF?","TF-IDF weights terms by their frequency in documents inversely proportional to their frequency across documents, highlighting distinctive words for each document."
"What is bag of words?","Bag of words represents text as word frequency vectors, ignoring grammar and word order, creating simple numerical representations for text classification."
"What is n-gram?","N-grams are contiguous sequences of n items from text, capturing local word order and common phrases beyond individual word frequencies."
"What is sentiment analysis?","Sentiment analysis classifies text by emotional tone or opinion, determining whether content is positive, negative, or neutral using NLP techniques."
"What is named entity recognition?","NER identifies and classifies named entities in text such as persons, organizations, locations, dates, and other predefined categories."
"What is part-of-speech tagging?","POS tagging assigns grammatical categories to words, labeling each token as noun, verb, adjective, etc., for syntactic analysis."
"What is sequence-to-sequence learning?","Seq2seq models map input sequences to output sequences of potentially different lengths, using encoder-decoder architectures for translation, summarization, etc."
"What is beam search?","Beam search explores multiple promising sequence generation paths simultaneously, keeping top-k candidates at each step to find high-probability outputs."
"What is teacher forcing?","Teacher forcing feeds true previous outputs as inputs during sequence training rather than model predictions, accelerating training but potentially causing exposure bias."
"What is object detection?","Object detection identifies and localizes multiple objects in images, predicting bounding boxes and class labels for each detected object instance."
"What is semantic segmentation?","Semantic segmentation classifies each pixel in images into categories, creating dense predictions that identify regions belonging to different object classes."
"What is instance segmentation?","Instance segmentation identifies individual object instances and their pixel-level boundaries, distinguishing between separate objects of the same class."
"What is image augmentation?","Image augmentation applies transformations like rotation, flipping, scaling, cropping, color jittering, or blurring to increase training data diversity and robustness."
"What is data poisoning?","Data poisoning injects malicious samples into training data to manipulate model behavior, causing misclassification or backdoors that activate on specific triggers."
"What is adversarial attack?","Adversarial attacks add imperceptible perturbations to inputs that cause models to make incorrect predictions, exploiting model vulnerabilities and sensitivity."
"What is adversarial training?","Adversarial training augments training data with adversarial examples, teaching models to resist attacks and improving robustness to input perturbations."
"What is model ensembling?","Model ensembling combines predictions from multiple models through voting, averaging, or stacking, leveraging diversity to improve accuracy and reduce variance."
"What is stacking in ML?","Stacking trains a meta-model on predictions from base models, learning to optimally combine their outputs for improved performance over individual models."
"What is blending in ML?","Blending combines model predictions using weights learned on a holdout set, similar to stacking but simpler and preventing overfitting to validation data."
"What is focal loss?","Focal loss down-weights easy examples and focuses training on hard negatives, addressing class imbalance by preventing overwhelming gradient contributions from easy samples."
"What is cosine similarity?","Cosine similarity measures vector angle rather than magnitude, ranging from -1 to 1, commonly used for comparing embeddings and document similarity."
"What is Euclidean distance?","Euclidean distance measures straight-line distance between points in feature space, commonly used in clustering, nearest neighbors, and similarity measurements."
"What is Manhattan distance?","Manhattan distance sums absolute differences across dimensions, measuring grid-like distance, being more robust to outliers than Euclidean distance."
"What is the Jaccard index?","Jaccard index measures set similarity by dividing intersection size by union size, used for comparing clusters, documents, or binary features."
"What is the Dice coefficient?","Dice coefficient measures overlap between sets by calculating twice their intersection divided by their total sizes, commonly used in image segmentation evaluation."
"What is IoU?","Intersection over Union measures bounding box overlap by dividing intersection area by union area, evaluating object detection accuracy with threshold-based matching."
"What is non-max suppression?","NMS eliminates redundant overlapping bounding boxes by keeping highest-confidence detections and suppressing similar boxes, cleaning up detection outputs."
"What is anchor boxes?","Anchor boxes are predefined bounding box templates at various scales and aspect ratios, serving as references that object detectors refine for predictions."
"What is region proposal?","Region proposals identify candidate object locations in images, generating potential bounding boxes that classifiers evaluate, as in R-CNN architectures."
"What is YOLO?","YOLO performs real-time object detection by dividing images into grids and predicting bounding boxes and classes directly in a single forward pass."
"What is R-CNN?","R-CNN uses selective search for region proposals, extracts CNN features from each region, and classifies with SVMs, pioneering deep learning for detection."
"What is Faster R-CNN?","Faster R-CNN integrates region proposal network with detection network, sharing computation and enabling end-to-end training for efficient accurate object detection."
"What is Mask R-CNN?","Mask R-CNN extends Faster R-CNN with segmentation masks, performing instance segmentation by adding a branch predicting pixel-level masks for each detection."
"What is residual network?","ResNets use skip connections that add inputs to outputs, enabling training of very deep networks by mitigating vanishing gradients and degradation problems."
"What is inception module?","Inception modules apply multiple filter sizes in parallel and concatenate results, capturing multi-scale features efficiently within a single layer."
"What is MobileNet?","MobileNet uses depthwise separable convolutions to reduce parameters and computation, enabling efficient deployment on mobile and embedded devices."
"What is EfficientNet?","EfficientNet systematically scales network depth, width, and resolution using compound scaling, achieving state-of-the-art accuracy with fewer parameters."
"What is neural network pruning?","Pruning removes unimportant weights or neurons based on magnitude, gradient, or other criteria, creating sparse networks that maintain accuracy with reduced complexity."
"What is lottery ticket hypothesis?","The lottery ticket hypothesis proposes that randomly initialized networks contain sparse subnetworks that can train to full accuracy when isolated early."
"What is neural architecture search?","NAS automatically discovers optimal architectures by searching design spaces using reinforcement learning, evolution, or differentiable methods, automating network design."
"What is mixed precision training?","Mixed precision training uses lower precision like FP16 for most operations while maintaining FP32 for critical steps, accelerating training with reduced memory."
"What is gradient accumulation?","Gradient accumulation computes gradients over multiple mini-batches before updating weights, simulating larger batch sizes when memory is limited."
"What is distributed training?","Distributed training parallelizes model training across multiple devices or machines, using data or model parallelism to handle large datasets and models."
"What is data parallelism?","Data parallelism replicates models across devices, processing different data batches in parallel and synchronizing gradients to update shared parameters."
"What is model parallelism?","Model parallelism splits model layers across devices when the model is too large for single device memory, with different devices processing different layers."
"What is pipeline parallelism?","Pipeline parallelism divides models into stages across devices, processing multiple micro-batches simultaneously in a pipeline to improve device utilization."
"What is zero redundancy optimizer?","ZeRO partitions optimizer states, gradients, and parameters across devices, reducing per-device memory while maintaining training efficiency through communication."
"What is few-shot prompting?","Few-shot prompting provides language models with a few examples in the prompt to demonstrate the task, enabling adaptation without parameter updates."
"What is zero-shot learning?","Zero-shot learning enables models to recognize classes never seen during training by leveraging auxiliary information like descriptions or attributes."
"What is prompt engineering?","Prompt engineering designs input prompts to elicit desired behaviors from language models, crafting instructions, examples, and context for optimal responses."
"What is in-context learning?","In-context learning allows language models to perform tasks by conditioning on examples and instructions in the prompt without updating weights."
"What is continual learning?","Continual learning trains models on sequential tasks while retaining knowledge from previous tasks, addressing catastrophic forgetting in non-stationary environments."
"What is catastrophic forgetting?","Catastrophic forgetting occurs when neural networks lose previously learned information upon learning new tasks, overwriting weights needed for earlier knowledge."
"What is elastic weight consolidation?","EWC prevents catastrophic forgetting by adding penalties for changing important weights, identifying critical parameters for previous tasks through Fisher information."
"What is online learning?","Online learning updates models incrementally as new data arrives in streams, adapting continuously without retraining from scratch on accumulated data."